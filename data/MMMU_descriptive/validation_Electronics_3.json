{
    "question": "Consider applying a unit ramp voltage source to a series RL circuit as shown in <image 1>. Compute the voltages $v_R (t)$ with zero initial condition for L = 0.1H;",
    "options": "['t + (1 / 10) (e^{-20t} - 1) V', 't + (1 / 20) (e^{-10t} - 1) V', 't + (1 / 10) (e^{-10t} - 1) V', 't - (1 / 10) (e^{-10t} - 1) V']",
    "id": "validation_Electronics_3",
    "description": "The image depicts a series RL circuit with a unit ramp voltage source applied to it. The circuit consists of a resistor (R) and an inductor (L) connected in series. The resistor has a resistance value of 1 ohm. The voltage source is represented by a graph showing a unit ramp function, where the voltage \\( v(t) \\) increases linearly with time starting from 0 at t=0 and reaching 1 volt at t=1 second. The voltage across the resistor is denoted as \\( V_R(t) \\), and the voltage across the inductor is denoted as \\( V_L(t) \\). The inductor has an inductance value of 0.1 henries (H).\n\nGiven this setup, the task is to compute the voltage \\( v_R(t) \\) across the resistor with zero initial conditions for the inductor. The options provided are:\n\nA. \\( t + \\frac{1}{10}(e^{-20t} - 1) \\) V\nB. \\( t + \\frac{1}{20}(e^{-10t} - 1) \\) V\nC. \\( t + \\frac{1}{10}(e^{-10t} - 1) \\) V\nD. \\( t - \\frac{1}{10}(e^{-10t} - 1) \\) V"
}